#pragma kernel Init
#pragma kernel Quantize

struct dispatch_args
{
    uint xGroups;
    uint yGroups;
    uint zGroups;
};

struct errorArr
{
    uint index;
    float error;
};

struct sorting_network_column
{
    uint first_element_index;
    uint group_stride;
    uint group_count;
    uint row_stride;
    uint row_count;
    uint comparisons_per_row;
    uint left_factor;
    uint right_offset;
};


extern uint e_seed;
extern uint e_arraySize;
extern uint e_dictSize;

groupshared uint g_numberOfSymbols;
groupshared uint g_used;

RWStructuredBuffer<dispatch_args> DispatchArgs;
RWStructuredBuffer<uint> SymbolCount;

RWStructuredBuffer<uint> TempBuffer;
RWStructuredBuffer<uint> OriginalBuffer;
RWStructuredBuffer<uint> DictBuffer;

RWStructuredBuffer<float> orig_prob;
RWStructuredBuffer<float> quant_prob;
RWStructuredBuffer<uint> quant_round;
RWStructuredBuffer<errorArr> ErrorCorr;

static uint s_numthreads = 256;

uint rand(uint s, uint seed, uint limit)
{
    s += seed;
    s ^= 2747636419u;
    s *= 2654435769u;
    s ^= s >> 16;
    s *= 2654435769u;
    s ^= s >> 16;
    s *= 2654435769u;
    return s & (limit - 1);
}

uint calcL(uint symbolCount)
{
    symbolCount--;
    
    uint counter = 0;
    
    while (symbolCount >  0)
    {
        symbolCount >>= 1;
        counter++;
    }

    return pow(2, counter + 1);
}

//**************************************************************
// HLSL Odd Even Merge Sort
// Written by Sergey Stepanov https://github.com/ref2401
// Used under MIT Liscence
// Added 9/16/2021
//**************************************************************

void compare_and_swap(uint l, uint r, RWStructuredBuffer<errorArr> _inBuffer)
{
    const errorArr x = _inBuffer[l];
    const errorArr y = _inBuffer[r];
    
    if (x.error <= y.error)
    {
        return;
    }
    
    _inBuffer[l] = y;
    _inBuffer[r] = x;
}

void process_column(uint curr_thread_id, sorting_network_column column, RWStructuredBuffer<errorArr> inBuffer)
{
    const uint comparisons_per_group = column.row_count * column.comparisons_per_row;
    const uint comparison_count = column.group_count * comparisons_per_group;
    const uint comparisons_per_thread = max(1, comparison_count / s_numthreads);
    const uint required_thread_count = uint(ceil(float(comparison_count) / comparisons_per_thread));
    
    if (curr_thread_id >= required_thread_count)
    {
        return;
    }
    
    const uint remained_comparison_count = comparison_count - comparisons_per_thread * s_numthreads;
    const uint cmpt_first_index = curr_thread_id * comparisons_per_thread;
    const uint cmpt_count = comparisons_per_thread + ((curr_thread_id + 1) / s_numthreads) * remained_comparison_count;
    
    for (uint i = 0; i < cmpt_count; i++)
    {
        const uint ci = cmpt_first_index + i;
        const uint gi = ci / comparisons_per_group;
        const uint ri = (ci % comparisons_per_group) / column.comparisons_per_row;
        const uint start_index = column.first_element_index
            + gi * column.group_stride
            + ri * column.row_stride;

        const uint l = start_index + column.left_factor * (ci % column.comparisons_per_row);
        const uint r = l + column.right_offset;
        compare_and_swap(l, r, inBuffer);
    }
}

void process_first_column(uint curr_thread_id, uint item_count, uint v_2power, RWStructuredBuffer<errorArr> inBuffer)
{
    const sorting_network_column column =
    {
		/* first_element_index */   0,
		/* uint group_stride */		0,
		/* uint group_count */		1,
		/* row_stride */			v_2power,
		/* row_count */				item_count / v_2power,
		/* comparisons_per_row */	v_2power >> 1,
		/* left_factor */			1,
		/* right_offset */			v_2power >> 1
    };
    
    process_column(curr_thread_id, column, inBuffer);
    DeviceMemoryBarrierWithGroupSync();
}

void process_intermediate_columns(uint curr_thread_id, uint item_count, uint v_2power, uint column_count, RWStructuredBuffer<errorArr> inBuffer)
{
    sorting_network_column column =
    {
		/* first_element_index */   v_2power >> 2,
		/* uint group_stride */		v_2power,
		/* uint group_count */		item_count / v_2power,
		/* row_stride */			v_2power >> 1,
		/* row_count */				1,
		/* comparisons_per_row */	v_2power >> 2,
		/* left_factor */			1,
		/* right_offset */			v_2power >> 2
    };
    
    for (uint ci = 0; ci < column_count; ++ci)
    {
        process_column(curr_thread_id, column, inBuffer);
        DeviceMemoryBarrierWithGroupSync();

        column.first_element_index >>= 1;
        column.row_stride >>= 1;
        column.row_count = 2 * column.row_count + 1;
        column.comparisons_per_row >>= 1;
        column.right_offset >>= 1;
    }
}

void process_last_column(uint curr_thread_id, uint item_count, uint v_2power, RWStructuredBuffer<errorArr> inBuffer)
{
    const sorting_network_column column =
    {
        /* first_element_index */   1,
		/* uint group_stride */		0,
		/* uint group_count */		1,
		/* row_stride */			v_2power,
		/* row_count */				item_count / v_2power,
		/* comparisons_per_row */	(v_2power >> 1) - 1,
		/* left_factor */			2,
		/* right_offset */			1
    };

    process_column(curr_thread_id, column, inBuffer);
    DeviceMemoryBarrierWithGroupSync();
}

void sort_4(uint curr_thread_id, uint item_count, RWStructuredBuffer<errorArr> inBuffer)
{
    const uint tuple_count = item_count >> 2;
    if (curr_thread_id >= tuple_count)
    {
        return;
    }
    
    const uint tuples_per_thread = max(1, tuple_count / s_numthreads);
    const uint origin = 4 * curr_thread_id * tuples_per_thread;
    
    for (uint t = 0; t < tuples_per_thread; ++t)
    {
        const uint idx0 = origin + 4 * t;
        const uint idx1 = idx0 + 1;
        const uint idx2 = idx1 + 1;
        const uint idx3 = idx2 + 1;

		// compare and swap: (0, 1) (2, 3) (0, 2) (1, 3) (1, 2) ---
        compare_and_swap(idx0, idx1, inBuffer);
        compare_and_swap(idx2, idx3, inBuffer);
        compare_and_swap(idx0, idx2, inBuffer);
        compare_and_swap(idx1, idx3, inBuffer);
        compare_and_swap(idx1, idx2, inBuffer);
    }
}

void SortMain(uint3 _gtid, RWStructuredBuffer<errorArr> inBuffer)
{
    sort_4(_gtid.x, e_arraySize, inBuffer);
    DeviceMemoryBarrierWithGroupSync();
    
    uint power = 3;
    uint v_2power = 8;
    
    while (v_2power <= e_arraySize)
    {
        process_first_column(_gtid.x, e_arraySize, v_2power, inBuffer);
        process_intermediate_columns(_gtid.x, e_arraySize, v_2power, power - 2, inBuffer);
        process_last_column(_gtid.x, e_arraySize, v_2power, inBuffer);
        
        ++power;
        v_2power <<= 1;
    }
}






[numthreads(256, 1, 1)]
void Init(uint3 id : SV_DispatchThreadID)
{
    uint threadWorkOne = ceil(e_dictSize * 1.0f / s_numthreads);
    uint threadWorkTwo = ceil(e_arraySize * 1.0f / s_numthreads);
    
    //first init
    uint tempOne = id.x * threadWorkOne;
    for (uint i = tempOne; i < (tempOne + threadWorkOne); i++)
    {
        if (i < e_dictSize)
        {
            TempBuffer[i] = rand(i, e_seed, e_arraySize);
        }
    }
    
    DeviceMemoryBarrierWithGroupSync();
    
    //second init
    
    uint tempTwo = id.x * threadWorkTwo;
    
    for (uint j = tempTwo; j < (tempTwo + threadWorkTwo); j++)
    {
        if (j < e_arraySize)
        {
            OriginalBuffer[j] = TempBuffer[rand(j, e_seed, e_dictSize)];
            DictBuffer[j] = 0;
        }
    }
    
    DeviceMemoryBarrierWithGroupSync();
    
    //count the frequency
    
    for (uint k = tempTwo; k < (tempTwo + threadWorkTwo); k++)
    {
        if (k < e_arraySize)
        {
            InterlockedAdd(DictBuffer[OriginalBuffer[k]], 1);
        }
    }
    
    DeviceMemoryBarrierWithGroupSync();
    
    //count the number of symbols
    
    for (uint l = tempTwo; l < (tempTwo + threadWorkTwo); l++)
    {
        if (l < e_arraySize)
        {
            if (DictBuffer[l] != 0)
            {
                InterlockedAdd(SymbolCount[0], 1);
            }
        }
    }
}

[numthreads(256, 1, 1)]
void Quantize(uint3 id : SV_DispatchThreadID, uint3 gtid : SV_GroupThreadID)
{
 
    //this is the quantized probability, the size of L is equal to the smallest power of two equal to or larger than the number of symbols, then doubled
    uint bigL = calcL(SymbolCount[0]);
    //for readability
    uint totalSymbolFrame = e_arraySize;
    
    //the multiplier to get the pre-rounded quantized probability
    double quantMult = bigL * 1.0 / totalSymbolFrame;
    
    uint workCount;
    uint empty;
    quant_prob.GetDimensions(workCount, empty);
    
    uint threadWorkOne = ceil(workCount * 1.0f / s_numthreads);
    uint tempOne = id.x * threadWorkOne;
    
    //generate initial quantization
    for (uint i = tempOne; i < tempOne + threadWorkOne; i++)
    {
        if(DictBuffer[i] != 0)
        {
            orig_prob[i] = DictBuffer[i] * 1.0f / totalSymbolFrame;
            //change this maybe
            quant_prob[i] = (float)(DictBuffer[i] * quantMult);
            quant_round[i] = round(quant_prob[i]);
            
            ErrorCorr[i].index = i;
            ErrorCorr[i].error = pow(quant_prob[i] - quant_round[i], 2) / orig_prob[i];
            
            g_used += quant_round[i];
        }
    }
    
    //correct for error
    if(g_used != bigL)
    {
        int sign;
        if(g_used > bigL)
        {
            sign = -1;
        }
        else
        {
            sign = 1;
        }
        
        //calculate potential error corrections
        for (uint i = tempOne; i < tempOne + threadWorkOne; i++)
        {
            ErrorCorr[i].error = ErrorCorr[i].error - (pow(quant_prob[i] - (quant_round[i] + sign), 2) / orig_prob[i]);
        }
    }

    DeviceMemoryBarrierWithGroupSync();
    
    if (g_used != bigL)
    {
        SortMain(gtid, ErrorCorr);
    }
    
    DeviceMemoryBarrierWithGroupSync();
}
